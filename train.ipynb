{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from ignite.engine import Engine, _prepare_batch, Events\n",
    "from ignite.metrics import Loss\n",
    "from ignite.handlers import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from Autoencoder import Autoencoder\n",
    "from dataloader import dataloader, train_transform\n",
    "from utils import show_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data path\n",
    "root = 'data/' \n",
    "\n",
    "# train settings\n",
    "num_epochs = 30\n",
    "batch_size = 8\n",
    "device = 'cpu'\n",
    "code_size = 64\n",
    "\n",
    "# verbose settings\n",
    "log_interval = 1\n",
    "save_images = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder(code_size).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "initial_lr = 0.001\n",
    "gamma = 0.8\n",
    "optimizer = torch.optim.Adam(model.parameters(), initial_lr)\n",
    "lr_scheduler = StepLR(optimizer, step_size=30, gamma=gamma)\n",
    "\n",
    "train_loader, val_loader, train_eval_loader = dataloader(root=root, \n",
    "                                            batch_size=batch_size)\n",
    "\n",
    "print('Train-size: ', len(train_loader.dataset))\n",
    "print('Test-size: ', len(val_loader.dataset))\n",
    "print('Train-eval-size: ', len(train_eval_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There I use ignite framework for wrap all pure python and pytorch training code\n",
    "# see more https://pytorch.org/ignite/index.html\n",
    "\n",
    "def create_unsupervised_evaluator(model, metrics={}, device=None):\n",
    "    if device:\n",
    "        model.to(device)\n",
    "\n",
    "    def _inference(engine, batch):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            x, _ = _prepare_batch(batch, device=device)\n",
    "            x_pred = model(x)\n",
    "            return x_pred, x\n",
    "\n",
    "    engine = Engine(_inference)\n",
    "\n",
    "    for name, metric in metrics.items():\n",
    "        metric.attach(engine, name)\n",
    "\n",
    "    return engine\n",
    "\n",
    "\n",
    "def process_function(engine, batch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    x, _ = _prepare_batch(batch, device=device)\n",
    "    x_pred = model(x)\n",
    "    loss = criterion(x_pred, x)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Engine(process_function)\n",
    "metrics = {\n",
    "    'avg_loss': Loss(criterion)\n",
    "}\n",
    "\n",
    "train_evaluator = create_unsupervised_evaluator(model, metrics=metrics, device=device)\n",
    "val_evaluator = create_unsupervised_evaluator(model, metrics=metrics, device=device)\n",
    "\n",
    "# log train loss after log_interval iterations\n",
    "@trainer.on(Events.ITERATION_COMPLETED)\n",
    "def log_training_loss(engine):\n",
    "    iteration = (engine.state.iteration - 1) % len(train_loader) + 1\n",
    "    if iteration % log_interval == 0:\n",
    "        print(\"Epoch[{}] Iteration[{}/{}] Loss: {:.4f}\"\n",
    "              .format(engine.state.epoch, \n",
    "                         iteration, \n",
    "                         len(train_loader), \n",
    "                         engine.state.output))\n",
    "\n",
    "\n",
    "# log train and validation loss and learning rate value after epoch\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def compute_and_display_val_metrics(engine):\n",
    "    metrics_val = val_evaluator.run(val_loader).metrics\n",
    "    metrics_train = train_evaluator.run(train_eval_loader).metrics\n",
    "    print(\"Epoch:{} Training Average Loss: {:.4f}, Validation Average Loss: {:.4f}, LR={:.7f}\"\n",
    "          .format(engine.state.epoch, \n",
    "                  metrics_val['avg_loss'], \n",
    "                  metrics_train['avg_loss'],\n",
    "                  float(optimizer.param_groups[0]['lr'])))\n",
    "\n",
    "    \n",
    "# make step for learning rate scheduler\n",
    "@trainer.on(Events.EPOCH_STARTED)\n",
    "def update_lr_scheduler(engine):\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "\n",
    "def score_function(engine):\n",
    "    return -1*engine.state.metrics['avg_loss']\n",
    "\n",
    "\n",
    "# save the best model comparing validation loss\n",
    "model_saver = ModelCheckpoint(\"best_models\",  \n",
    "                                   filename_prefix=\"autoencoder\",\n",
    "                                   score_name=\"loss\",  \n",
    "                                   score_function=score_function,\n",
    "                                   n_saved=1,\n",
    "                                   save_as_state_dict=True,\n",
    "                                   create_dir=True)\n",
    "val_evaluator.add_event_handler(Events.COMPLETED, \n",
    "                                model_saver, \n",
    "                                {\"model\": model})\n",
    "\n",
    "\n",
    "# also save one model and configuration after each epoch\n",
    "training_saver = ModelCheckpoint(\"checkpoint\",\n",
    "                                 filename_prefix=\"checkpoint\",\n",
    "                                 save_interval=1,\n",
    "                                 n_saved=1,\n",
    "                                 save_as_state_dict=True,\n",
    "                                 create_dir=True)\n",
    "to_save = {\n",
    "    \"model\": model, \n",
    "    \"optimizer\": optimizer, \n",
    "    \"lr_scheduler\": lr_scheduler\n",
    "} \n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, training_saver, to_save)\n",
    "\n",
    "\n",
    "# stop if there is no improvements in validation loss in 10 epochs\n",
    "early_stopping = EarlyStopping(patience=10,     \n",
    "                              score_function=score_function, \n",
    "                              trainer=trainer)\n",
    "val_evaluator.add_event_handler(Events.EPOCH_COMPLETED, early_stopping)\n",
    "\n",
    "# save 10 original and decoded images after each epoch\n",
    "if save_images:\n",
    "    if not os.path.exists('images/'):\n",
    "        os.mkdir('images/')\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def save_images(engine):\n",
    "        model.eval()\n",
    "        epoch = engine.state.epoch\n",
    "        np.random.seed(46)\n",
    "        for i in np.random.random_integers(0, len(val_loader), 10):\n",
    "            image, _ = val_loader.dataset[i]\n",
    "            image = image.to(device)\n",
    "            with torch.no_grad():\n",
    "                predict_image = model(image[None])[0].detach().cpu()\n",
    "            plt.subplot(1, 2, 1)\n",
    "            show_image(np.swapaxes(image.cpu().numpy(), 0, 2))\n",
    "            plt.subplot(1, 2, 2)\n",
    "            show_image(np.swapaxes(predict_image.numpy(), 0, 2))\n",
    "            plt.savefig('images/{}_{}'.format(epoch, i))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.run(train_loader, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
